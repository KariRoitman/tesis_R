---
title: "Untitled"
author: "Karina Roitman"
date: "2025-01-19"
output: html_document
---

---
title: "Ranger"
author: "Karina Roitman"
date: "2025-01-14"
output: html_document
---


```{r}
library(keras)
library(tensorflow)
library(reticulate)
library(caret)
```

COMBAT_CORRECTED_matrix_DICHO

```{r}
Train.rf_matrix_dico  <- as.data.frame(trainData_matrix_dico) 

Test.rf_matrix_dico <- as.data.frame(testData_matrix_dico)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_matrix_dico)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_matrix_dico)

Train.rf_matrix_dico <- bake(trained_recipe, new_data = Train.rf_matrix_dico)
Test.rf_matrix_dico  <- bake(trained_recipe, new_data = Test.rf_matrix_dico)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_matrix_dico[, -ncol(Train.rf_matrix_dico)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, smatrix(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = smatrix(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_matrix_dico$Y <- factor(as.numeric(factor(Train.rf_matrix_dico$Y)))
Train.rf_matrix_dico$Y <- factor(Train.rf_matrix_dico$Y, levels = c("1", "2"))
levels(Train.rf_matrix_dico$Y) <- make.names(levels(Train.rf_matrix_dico$Y))

```





```{r}
class(Train.rf_matrix_dico)
```


```{r}
Train.rf_matrix_dico <- as.data.frame(Train.rf_matrix_dico)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_matrix_dico <- as.data.frame(Train.rf_matrix_dico)

# Convertimos Y a factor
Train.rf_matrix_dico$Y <- as.factor(Train.rf_matrix_dico$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_matrix_dico <- caret::train(Y ~ .,
                data = Train.rf_matrix_dico, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  # Aquí estaba el error, había texto adicional

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_matrix_dico$Y<-as.factor(Test.rf_matrix_dico$Y)
str(Test.rf_matrix_dico$Y)
```

```{r}
testRF_NOID_matrix_dico <- Test.rf_matrix_dico[, -which(names(Test.rf_matrix_dico) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_matrix_dico<-predict(results_matrix_dico, newdata = testRF_NOID_matrix_dico)#matriz binarizada
print(predRANGER_matrix_dico)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger <- predict(results_matrix_dico, newdata = testRF_NOID_matrix_dico, type = "prob")

colnames(prob_predRanger)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_matrix_dico$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_matrix_dich <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_matrix_dich, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_matrix_dico, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_matrix_dic <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_matrix_dic,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_matrix_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_matrix_dic,2)))

# Especificidad (TNR)
specificity_RANGER_matrix_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_matrix_dic,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_matrix_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_matrix_dic,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_matrix_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_matrix_dic,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGERmatrix_dic <- kappa2(cbind(predRANGER_matrix_dico, Test.rf_matrix_dico$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGERmatrix_dic$value, 3)))
kappa_RANGERmatrix_dic<-round(kappa_RANGERmatrix_dic$value, 3)
```


COMBAT CORRECTED matrix




```{r}
Train.rf_matrix  <- as.data.frame(trainData_matrix) 

Test.rf_matrix <- as.data.frame(testData_matrix)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_matrix)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_matrix)

Train.rf_matrix <- bake(trained_recipe, new_data = Train.rf_matrix)
Test.rf_matrix  <- bake(trained_recipe, new_data = Test.rf_matrix)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_matrix[, -ncol(Train.rf_matrix)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, smatrix(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = smatrix(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_matrix$Y <- factor(as.numeric(factor(Train.rf_matrix$Y)))
Train.rf_matrix$Y <- factor(Train.rf_matrix$Y, levels = c("1", "2"))
levels(Train.rf_matrix$Y) <- make.names(levels(Train.rf_matrix$Y))

```





```{r}
class(Train.rf_matrix)
```


```{r}
Train.rf_matrix <- as.data.frame(Train.rf_matrix)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_matrix <- as.data.frame(Train.rf_matrix)

# Convertimos Y a factor
Train.rf_matrix$Y <- as.factor(Train.rf_matrix$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_matrix <- caret::train(Y ~ .,
                data = Train.rf_matrix, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_matrix$Y<-as.factor(Test.rf_matrix$Y)
str(Test.rf_matrix$Y)
```

```{r}
testRF_NOID_matrix <- Test.rf_matrix[, -which(names(Test.rf_matrix) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_matrix<-predict(results_matrix, newdata = testRF_NOID_matrix)#matriz binarizada
print(predRANGER_matrix)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger_matrix <- predict(results_matrix, newdata = testRF_NOID_matrix, type = "prob")

colnames(prob_predRanger_matrix)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_matrix$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger_matrix[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_matrix <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_matrix, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_matrix, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_matrix <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_matrix,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_matrix <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_matrix,2)))

# Especificidad (TNR)
specificity_RANGER_matrix <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_matrix,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_matrix<- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_matrix,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_matrix<- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_matrix,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGERmatrix <- kappa2(cbind(predRANGER_matrix, Test.rf_matrix$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGERmatrix$value, 3)))
kappa_RANGERmatrix<-round(kappa_RANGERmatrix$value, 3)
```

