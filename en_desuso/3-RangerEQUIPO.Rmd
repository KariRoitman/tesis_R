---
title: "Ranger"
author: "Karina Roitman"
date: "2025-01-14"
output: html_document
---


```{r}
library(keras)
library(tensorflow)
library(reticulate)
library(caret)
```

COMBAT_CORRECTED_EQUIPO_DICHO

```{r}
Train.rf_equipo_dico  <- as.data.frame(trainData_equipo_dico) 

Test.rf_equipo_dico <- as.data.frame(testData_equipo_dico)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_equipo_dico)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_equipo_dico)

Train.rf_equipo_dico <- bake(trained_recipe, new_data = Train.rf_equipo_dico)
Test.rf_equipo_dico  <- bake(trained_recipe, new_data = Test.rf_equipo_dico)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_equipo_dico[, -ncol(Train.rf_equipo_dico)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, seq(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = seq(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_equipo_dico$Y <- factor(as.numeric(factor(Train.rf_equipo_dico$Y)))
Train.rf_equipo_dico$Y <- factor(Train.rf_equipo_dico$Y, levels = c("1", "2"))
levels(Train.rf_equipo_dico$Y) <- make.names(levels(Train.rf_equipo_dico$Y))

```





```{r}
class(Train.rf_equipo_dico)
```


```{r}
Train.rf_equipo_dico <- as.data.frame(Train.rf_equipo_dico)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_equipo_dico <- as.data.frame(Train.rf_equipo_dico)

# Convertimos Y a factor
Train.rf_equipo_dico$Y <- as.factor(Train.rf_equipo_dico$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_equipo_dico <- caret::train(Y ~ .,
                data = Train.rf_equipo_dico, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  # Aquí estaba el error, había texto adicional

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_equipo_dico$Y<-as.factor(Test.rf_equipo_dico$Y)
str(Test.rf_equipo_dico$Y)
```

```{r}
testRF_NOID_equipo_dico <- Test.rf_equipo_dico[, -which(names(Test.rf_equipo_dico) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_equipo_dico<-predict(results_equipo_dico, newdata = testRF_NOID_equipo_dico)#matriz binarizada
print(predRANGER_equipo_dico)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger <- predict(results_equipo_dico, newdata = testRF_NOID_equipo_dico, type = "prob")

colnames(prob_predRanger)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_equipo_dico$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_equipo_dich <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_equipo_dich, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_equipo_dico, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_eq_dic <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_eq_dic,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_eq_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_eq_dic,2)))

# Especificidad (TNR)
specificity_RANGER_eq_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_eq_dic,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_eq_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_eq_dic,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_eq_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_eq_dic,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGEReq_dic <- kappa2(cbind(predRANGER_equipo_dico, Test.rf_equipo_dico$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGEReq_dic$value, 3)))
kappa_RANGEReq_dic<-round(kappa_RANGEReq_dic$value, 3)
```


COMBAT CORRECTED EQUIPO




```{r}
Train.rf_equipo  <- as.data.frame(trainData_equipo) 

Test.rf_equipo <- as.data.frame(testData_equipo)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_equipo)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_equipo)

Train.rf_equipo <- bake(trained_recipe, new_data = Train.rf_equipo)
Test.rf_equipo  <- bake(trained_recipe, new_data = Test.rf_equipo)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_equipo[, -ncol(Train.rf_equipo)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, seq(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = seq(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_equipo$Y <- factor(as.numeric(factor(Train.rf_equipo$Y)))
Train.rf_equipo$Y <- factor(Train.rf_equipo$Y, levels = c("1", "2"))
levels(Train.rf_equipo$Y) <- make.names(levels(Train.rf_equipo$Y))

```





```{r}
class(Train.rf_equipo)
```


```{r}
Train.rf_equipo <- as.data.frame(Train.rf_equipo)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_equipo <- as.data.frame(Train.rf_equipo)

# Convertimos Y a factor
Train.rf_equipo$Y <- as.factor(Train.rf_equipo$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_equipo <- caret::train(Y ~ .,
                data = Train.rf_equipo, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_equipo$Y<-as.factor(Test.rf_equipo$Y)
str(Test.rf_equipo$Y)
```

```{r}
testRF_NOID_equipo <- Test.rf_equipo[, -which(names(Test.rf_equipo) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_equipo<-predict(results_equipo, newdata = testRF_NOID_equipo)#matriz binarizada
print(predRANGER_equipo)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger_equipo <- predict(results_equipo, newdata = testRF_NOID_equipo, type = "prob")

colnames(prob_predRanger_equipo)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_equipo$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger_equipo[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_equipo <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_equipo, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_equipo, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_eq <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_eq,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_eq <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_eq,2)))

# Especificidad (TNR)
specificity_RANGER_eq <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_eq,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_eq<- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_eq,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_eq<- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_eq,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGEReq <- kappa2(cbind(predRANGER_equipo, Test.rf_equipo$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGEReq$value, 3)))
kappa_RANGEReq<-round(kappa_RANGEReq$value, 3)
```
