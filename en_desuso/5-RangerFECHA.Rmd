---
title: "5-Ranger FECHA"
author: "Karina Roitman"
date: "2025-01-19"
output: html_document
---

---
title: "Ranger"
author: "Karina Roitman"
date: "2025-01-14"
output: html_document
---


```{r}
library(keras)
library(tensorflow)
library(reticulate)
library(caret)
```

COMBAT_CORRECTED_FECHA_DICHO

```{r}
Train.rf_fecha_dico  <- as.data.frame(trainData_fecha_dico) 

Test.rf_fecha_dico <- as.data.frame(testData_fecha_dico)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_fecha_dico)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_fecha_dico)

Train.rf_fecha_dico <- bake(trained_recipe, new_data = Train.rf_fecha_dico)
Test.rf_fecha_dico  <- bake(trained_recipe, new_data = Test.rf_fecha_dico)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_fecha_dico[, -ncol(Train.rf_fecha_dico)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, sfecha(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = sfecha(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_fecha_dico$Y <- factor(as.numeric(factor(Train.rf_fecha_dico$Y)))
Train.rf_fecha_dico$Y <- factor(Train.rf_fecha_dico$Y, levels = c("1", "2"))
levels(Train.rf_fecha_dico$Y) <- make.names(levels(Train.rf_fecha_dico$Y))

```





```{r}
class(Train.rf_fecha_dico)
```


```{r}
Train.rf_fecha_dico <- as.data.frame(Train.rf_fecha_dico)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_fecha_dico <- as.data.frame(Train.rf_fecha_dico)

# Convertimos Y a factor
Train.rf_fecha_dico$Y <- as.factor(Train.rf_fecha_dico$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_ranger_fecha_dic <- caret::train(Y ~ .,
                data = Train.rf_fecha_dico, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  # Aquí estaba el error, había texto adicional

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_fecha_dico$Y<-as.factor(Test.rf_fecha_dico$Y)
str(Test.rf_fecha_dico$Y)
```

```{r}
testRF_NOID_fecha_dico <- Test.rf_fecha_dico[, -which(names(Test.rf_fecha_dico) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_fecha_dic<-predict(results_ranger_fecha_dic, newdata = testRF_NOID_fecha_dico)#matriz binarizada
print(predRANGER_fecha_dic)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger_fecha_dic <- predict(results_ranger_fecha_dic, newdata = testRF_NOID_fecha_dico, type = "prob")

colnames(prob_predRanger_fecha_dic)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_fecha_dico$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger_fecha_dic[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_FECHA_dich <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_FECHA_dich, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_fecha_dic, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_fecha_dic <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_fecha_dic,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_fecha_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_fecha_dic,2)))

# Especificidad (TNR)
specificity_RANGER_fecha_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_fecha_dic,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_fecha_dic <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_fecha_dic,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_fecha_dic <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_fecha_dic,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGERfecha_dic <- kappa2(cbind(predRANGER_fecha_dic, Test.rf_fecha_dico$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGERfecha_dic$value, 3)))
kappa_RANGERfecha_dic<-round(kappa_RANGERfecha_dic$value, 3)
```


COMBAT CORRECTED FECHA




```{r}
Train.rf_FECHA  <- as.data.frame(trainData_fecha) 

Test.rf_FECHA <- as.data.frame(testData_fecha)
```

```{r}
objeto_recipe <- recipe(formula = Y ~ .,
                        data =  Train.rf_FECHA)

objeto_recipe <- objeto_recipe %>% 
  step_nzv(all_predictors())

trained_recipe <- prep(objeto_recipe, training = Train.rf_FECHA)

Train.rf_FECHA <- bake(trained_recipe, new_data = Train.rf_FECHA)
Test.rf_FECHA  <- bake(trained_recipe, new_data = Test.rf_FECHA)
```

```{r}
# Submuestras y repeticiones

# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

x <- Train.rf_FECHA[, -ncol(Train.rf_FECHA)] # se incluyen todas las columnas excepto la última

# if(ncol(x) <= 7){
#   
#   mtry <- c(1, 2, 3)
#   
# } else {
#   
#   mtry <- c(1, 2, sfecha(4, ncol(x) * 0.8, 2))
#   
# }
mtry <- c(1, 2, 3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry,
                               #min.node.size = sfecha(1, 30, 2),
                               min.node.size=min.node.size,
                               splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

Train.rf_FECHA$Y <- factor(as.numeric(factor(Train.rf_FECHA$Y)))
Train.rf_FECHA$Y <- factor(Train.rf_FECHA$Y, levels = c("1", "2"))
levels(Train.rf_FECHA$Y) <- make.names(levels(Train.rf_FECHA$Y))

```





```{r}
class(Train.rf_FECHA)
```


```{r}
Train.rf_FECHA <- as.data.frame(Train.rf_FECHA)
```


```{r}
# Primero aseguramos que Train.rf es un dataframe
Train.rf_FECHA <- as.data.frame(Train.rf_FECHA)

# Convertimos Y a factor
Train.rf_FECHA$Y <- as.factor(Train.rf_FECHA$Y)

# Definimos número de árboles
#n_trees <- 500 # default
n_trees<-200
# Establecemos semilla para reproducibilidad
set.seed(80)

# Ejecutamos el entrenamiento
results_FECHA <- caret::train(Y ~ .,
                data = Train.rf_FECHA, 
                method = "ranger",
                tuneGrid = hiperparametros,
                metric = "Accuracy",
                importance = "impurity",
                trControl = cross_val,
                num.trees = n_trees)
               #allowParallel=FALSE)  

# Vector para probar diferentes números de árboles
#num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500)

```




```{r}
Test.rf_FECHA$Y<-as.factor(Test.rf_FECHA$Y)
str(Test.rf_FECHA$Y)
```

```{r}
testRF_NOID_FECHA <- Test.rf_FECHA[, -which(names(Test.rf_FECHA) == "Y")]

```



```{r}
#prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test)
predRANGER_FECHA<-predict(results_FECHA, newdata = testRF_NOID_FECHA)#matriz binarizada
print(predRANGER_FECHA)


# Obtener las etiquetas reales del conjunto de datos de prueba
#y_test <- testData$Y

prob_predRanger_FECHA <- predict(results_FECHA, newdata = testRF_NOID_FECHA, type = "prob")

colnames(prob_predRanger_FECHA)
# Asegúrate de que y_test sea un factor con los niveles correctos
y_test <- factor(Test.rf_FECHA$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos"))




```


```{r}
library(pROC)

# Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2
y_test_numeric <- as.numeric(y_test)

roc_curve <- roc(response = y_test_numeric, 
                 predictor = prob_predRanger_FECHA[, "X2"], 
                 levels = c(1, 2))
AUC_Ranger_FECHA <- auc(roc_curve)
print(paste("El valor de AUC es:", round(AUC_Ranger_FECHA, 3)))

# Visualiza la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

confusion_matrixRANGER <- table(predRANGER_FECHA, y_test)
# Imprimir la matriz de confusión
print(confusion_matrixRANGER)
```

```{r}
# Precisión (Accuracy)
accuracy_RANGER_fecha <- sum(diag(confusion_matrixRANGER)) / sum(confusion_matrixRANGER)
print(paste("La precisión (Accuracy) es:", round(accuracy_RANGER_fecha,2)))

# Sensibilidad (Recall o TPR)
sensitivity_RANGER_fecha <- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[, 2])
print(paste("La sensibilidad es:", round(sensitivity_RANGER_fecha,2)))

# Especificidad (TNR)
specificity_RANGER_fecha <- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[, 1])
print(paste("la especificidad es:", round(specificity_RANGER_fecha,2)))

# Valor Predictivo Positivo (PPV o Precision)
ppv_RANGER_fecha<- confusion_matrixRANGER[2, 2] / sum(confusion_matrixRANGER[2, ])
print(paste("el VPP es:", round(ppv_RANGER_fecha,2)))

# Valor Predictivo Negativo (VPN)
npv_RANGER_fecha<- confusion_matrixRANGER[1, 1] / sum(confusion_matrixRANGER[1, ])
print(paste("el VPN es: ",  round(npv_RANGER_fecha,2)))


```


```{r}

library(irr)

# Calcular Kappa
kappa_RANGERfecha <- kappa2(cbind(predRANGER_FECHA, Test.rf_FECHA$Y))

# Ver el valor de Kappa
print(paste("El índice Kappa es:", round(kappa_RANGERfecha$value, 3)))
kappa_RANGERfecha<-round(kappa_RANGERfecha$value, 3)
```

