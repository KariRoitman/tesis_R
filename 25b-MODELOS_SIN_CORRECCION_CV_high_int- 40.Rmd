---
title: "SIN CORRECCION"
author: "Karina Roitman"
date: "2024-10-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Modelos sin corrección de efecto batch

```{r}
library(MALDIquant)
library(MALDIquantForeign)
library(readBrukerFlexData)
library(ggplot2)
library(caret)
library(stats)
library(binda)
library(factoextra)
library(binda)
library(dplyr)
library(crossval)
library(ggrepel)
library(corrr)
library(ggplot2)
library(FactoMineR)
```

sin dicotomizar


```{r}
library(dplyr)

# Eliminar la columna 'label' usando dplyr
#featureMatrix <- featureMatrix %>% select(-label)


```



```{r}
# Renombrar la columna 'label' a 'Y' y convertirla en factor
#names(featureMatrix_bind)[names(featureMatrix_bind) == "covid"] <- "Y"

featureMatrix_bind <- as.data.frame(featureMatrix_bind)
str(featureMatrix_bind)

# Verificar estructura del dataframe después de los cambios


```



# Modelos desde matriz dicotomizada sin corregir por batch


```{r}

featureMatrix_bind<-as.data.frame(featureMatrix_bind)
#featureMatrix_bind$label <- as.factor(featureMatrix_bind$label)
```

```{r}

library(tidymodels)
# set.seed asegura reproducibilidad
set.seed(42)

#Utilizo tidymodels para dividir de manera proporcional

split_data <- initial_split(featureMatrix_bind, strata = "Y", prop = 0.8)

# Obtener los conjuntos de entrenamiento y prueba
trainData_matriz <- training(split_data)
testData_matriz <- testing(split_data)

```

```{r}
trainData_matriz_dico<-as.data.frame(trainData_matriz)
trainData_matriz_dico$Y<-as.factor(trainData_matriz$Y)
str(trainData_matriz)
```

```{r}
train_subset_matriz <- trainData_matriz[, -ncol(trainData_matriz)]
```





```{r}
trainData_matriz<- cbind(train_subset_matriz, trainData_matriz$Y)#1=neg,2=pos
```



```{r}
library(dplyr)
trainData_matriz <- trainData_matriz %>% rename(Y = ncol(trainData_matriz))
str(trainData_matriz$Y)
```


```{r}
trainData_matriz<-as.data.frame(trainData_matriz)
trainData_matriz$Y<-as.factor(trainData_matriz$Y)
str(trainData_matriz)
```

```{r}
labels <- trainData_matriz$Y

#Definir número de bootstraps
n_boot <- 10
set.seed(123)

#Inicializar lista para guardar umbrales
thresholds_list <- vector("list", n_boot)

#  Ejecutar bootstrap
for (i in 1:n_boot) {
  sample_indices <- sample(1:nrow(train_subset_matriz), replace = TRUE)
  sampled_data <- train_subset_matriz[sample_indices, ]
  sampled_labels <- labels[sample_indices]

  thresholds <- optimizeThreshold(sampled_data, sampled_labels)
  thresholds_list[[i]] <- thresholds
}

# Unir todos los umbrales en un data frame
thresholds_df <- do.call(rbind, thresholds_list)

# Calcular el CV de cada pico
cv_thresholds <- apply(thresholds_df, 2, function(x) {
  media <- mean(x, na.rm = TRUE)
  sd <- sd(x, na.rm = TRUE)
  if (media == 0) return(Inf) else return((sd / media) * 100)
})

#Seleccionar los picos con CV < 40 (estables)
picos_estables <- names(cv_thresholds[cv_thresholds < 40])

#  Filtrar la matriz original para quedarte solo con esos picos
train_subset_matriz <- train_subset_matriz[, picos_estables]

#  Volver a combinar con la variable Y
#train_subset_fecha$Y <- labels
```



```{r}
trainData_matriz<- cbind(train_subset_matriz, trainData_matriz$Y)#1=neg,2=pos
```


```{r}
trainData_matriz <- trainData_matriz %>% rename(Y = ncol(trainData_matriz))

trainData_matriz<-as.data.frame(trainData_matriz)

```

```{r}
# Especificar la variable dependiente en la fórmula
formula <- Y ~ .
```



```{r}
# Submuestras y repeticiones
set.seed(42)
# particiones  <- 5
# repeticiones <- 15
particiones <- 3
repeticiones <- 5
```


# Random forest

```{r}
# Specify the tunning configuration (mtry hyperparameter depends on the number of columns)
seed.rf <- 42
set.seed(seed.rf) 

mtry <- c(1,2,3)
min.node.size <- seq(1, 10, 2)  # Reducir el rango
hiperparametros <- expand.grid(mtry =  mtry)
                               #min.node.size = seq(1, 30, 2),
                               #min.node.size=min.node.size,
                               #splitrule = "gini")
```


```{r}

# Seeds
seed.rf <- 42
set.seed(seed.rf)

seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)

for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(500, nrow(hiperparametros)) 
}
# genera un vector de nrow(hiperparametros) números aleatorios entre 1 y 500.
#Esto asegura que cada combinación de hiperparámetros tenga una semilla diferente en cada iteración.

seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1)

# Training control
```



```{r}
# Training control

cross_val_rf <- trainControl(
  method = "repeatedcv",
  number = particiones,
  repeats = repeticiones,
  returnResamp = "final",
  verboseIter = FALSE,
  allowParallel = TRUE,
  classProbs = TRUE,
  seeds = seeds)

# Training 

# Convertir los niveles de Train.rf$sensi a números también

trainData_matriz$Y <- factor(as.numeric(factor(trainData_matriz$Y)))
trainData_matriz$Y <- factor(trainData_matriz$Y, levels = c("1", "2"))
levels(trainData_matriz$Y) <- make.names(levels(trainData_matriz$Y))

```






```{r}
library(caret)

# 
# RF <- caret::train(Y ~ ., data = trainData, 
#                       method = "rf",   # Método para random forest
#                       trControl = cross_val, 
#                       tuneGrid = grid_rf,  # Parámetro mtry
#                       metric = "Accuracy")  # Métrica para clasificación
RF_matrix_nodic_cargafx <- function(df_train, model, grid, metrica = "Accuracy", control) {

  
  # Entrenar el modelo
  RF_matrix_carga <- caret::train(
    Y ~ .,
    data = df_train,
    method = model,
    tuneGrid = grid,
    metric = metrica,
    trControl = control
  )
  
  # Mostrar resumen
  print(RF_matrix_carga)
  plot(RF_matrix_carga)
  
  # Guardar resultado
  #save(RF_equipo, file = paste0(title, ".rda"))
  
  return(RF_matrix_carga)
}

RF_matrix_carga<-RF_matrix_nodic_cargafx(df_train=trainData_matriz, model="rf", grid=hiperparametros, metrica="Accuracy", control=cross_val_rf )
print(RF_matrix_carga)
```

```{r}
RF_matrix_carga
```

```{r}
plot(RF_matrix_carga)
```


```{r}
# ciegoMatrix_nodic_carga <- featureMatrix_bind %>%
#   rename(Y = label)
```

```{r}
ciego_data <- as.data.frame(featureMatrix_ciegos_total)
ciego_data<- ciego_data[, colnames(trainData_matriz)]
# Si viene con columna Y (conocida), separala:
if ("Y" %in% colnames(ciego_data)) {
  Y_ciego <- ciego_data$Y
  X_ciego <- ciego_data[, setdiff(colnames(ciego_data), "Y")]
} else {
  X_ciego <- ciego_data
  Y_ciego <- NULL
}



```



```{r}
# Predicciones (clase)
predicciones_ciego_matrix_carga <- predict(RF_matrix_carga, newdata = X_ciego)
levels(predicciones_ciego_matrix_carga) <- c("Cov.Neg", "Cov.Pos")

# Predicciones (probabilidades)
prob_ciego <- predict(RF_matrix_carga, newdata = X_ciego, type = "prob")
prob_ciego <- prob_ciego %>%
  dplyr::select(X1, X2) %>%
  rename(Cov.Neg = "X1", Cov.Pos = "X2")



  # Confusion matrix
ciego_matrix_rf_carga<-caret::confusionMatrix(predicciones_ciego_matrix_carga, Y_ciego, positive = "Cov.Pos")

  # AUC
  library(pROC)
  Y_ciego_num <- as.numeric(Y_ciego)
  roc_ciego <- roc(Y_ciego_num, prob_ciego[, "Cov.Pos"])
  plot(roc_ciego, main = "ROC en Datos Ciegos", col = "darkgreen", lwd = 2)
  AUC_RF_carga_ciego<-auc(roc_ciego)
  

accuracyRF_carga_ciego <- ciego_matrix_rf_carga$overall["Accuracy"]
kappaRF_carga_ciego <- ciego_matrix_rf_carga$overall["Kappa"]
# Métricas por clase
sensitivityRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Sensitivity"]
specificityRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Specificity"]
precisionRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Pos Pred Value"]
recallRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Sensitivity"]  # Igual a sensitivity
f1_scoreRF_carga_ciego <- ciego_matrix_rf_carga$byClass["F1"]
npvRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Neg Pred Value"]
prevalenceRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Prevalence"]
detection_rateRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Detection Rate"]
balanced_accuracyRF_carga_ciego <- ciego_matrix_rf_carga$byClass["Balanced Accuracy"]

# Calcular LR+ y LR- que no vienen directamente en confusionMatrix
LR_plusRF_carga_ciego <- sensitivityRF_carga_ciego / (1 - specificityRF_carga_ciego)
LR_minusRF_carga_ciego <- (1 - sensitivityRF_carga_ciego) / specificityRF_carga_ciego

# Para manejar valores especiales
LR_plusRF_carga_ciego <- ifelse(is.nan(LR_plusRF_carga_ciego) | is.infinite(LR_plusRF_carga_ciego), NA, LR_plusRF_carga_ciego)
LR_minusRF_carga_ciego <- ifelse(is.nan(LR_minusRF_carga_ciego) | is.infinite(LR_minusRF_carga_ciego), NA, LR_minusRF_carga_ciego)

# Crear un dataframe con todas las métricas
metricsRF_matrix_carga_ciego_cv <- data.frame(
  Metric = c("Accuracy", "Kappa", "Sensitivity", "Specificity", "Precision", 
             "F1_Score", "NPV", "Prevalence", "Detection_Rate", 
             "Balanced_Accuracy", "LR+", "LR-", "AUC"),
  RF_matrix_carga_rf_cv = c(accuracyRF_carga_ciego, kappaRF_carga_ciego, sensitivityRF_carga_ciego, specificityRF_carga_ciego, precisionRF_carga_ciego, 
            f1_scoreRF_carga_ciego, npvRF_carga_ciego, prevalenceRF_carga_ciego, detection_rateRF_carga_ciego, 
            balanced_accuracyRF_carga_ciego, LR_plusRF_carga_ciego, LR_minusRF_carga_ciego, AUC_RF_carga_ciego))

# Mostrar los resultados
print(metricsRF_matrix_carga_ciego_cv)
  
```





<!-- # Prediccion GLM -->

<!-- ```{r} -->
<!-- #prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test) -->
<!-- predGLM_matrix_carga<-predict(GLM_matrix_carga, newdata = testData_NOID)#matriz binarizada -->
<!-- print(predGLM_matrix_carga) -->

<!-- predGLM_matrix_carga <- factor(as.character(predGLM_matrix_carga),  -->
<!--                              levels = c("X1", "X2"), -->
<!--                              labels = c("1", "2")) -->
<!-- predGLM_matrix_carga <- factor(predGLM_matrix_carga, levels = c("1", "2"), labels = c("Cov.Neg", "Cov.Pos")) -->


<!-- # Obtener las etiquetas reales del conjunto de datos de prueba -->
<!-- y_test <- testData$Y -->
<!-- #y_testDIC <- FeatureMatrix_Dic_df$Y#Matriz binarizada -->

<!-- ``` -->

<!-- ```{r} -->
<!-- GLM_metrics_matrix_carga <- caret::confusionMatrix(predGLM_matrix_carga, y_test, positive = "Cov.Pos") -->
<!-- ``` -->


<!-- ```{r} -->


<!-- # Predicciones probabilísticas con el modelo GLM -->
<!-- prob_predGLM <- predict(GLM_matrix_carga, newdata = testData_NOID, type = "prob") -->

<!-- # Verifica los nombres de las columnas (clases) -->
<!-- print(colnames(prob_predGLM))  # Deberían ser "1" y "2" o los nombres de las clases -->

<!-- # Asegúrate de que y_test sea numérico con niveles 1 y 2 -->
<!-- y_test_numeric <- as.numeric(testData$Y) -->

<!-- # Calcula la curva ROC usando la probabilidad de la clase positiva ("2") -->
<!-- roc_curve_glm <- roc(response = y_test_numeric, predictor = prob_predGLM[, "X2"], levels = c(1, 2)) -->

<!-- # Calcula el AUC -->
<!-- AUC_GLM_matrix_carga <- auc(roc_curve_glm) -->
<!-- print(paste("El valor de AUC es:", round(AUC_GLM_matrix_carga, 3))) -->

<!-- # Visualiza la curva ROC -->
<!-- plot(roc_curve_glm, main = "Curva ROC - GLM", col = "red", lwd = 2) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- library(caret) -->
<!-- accuracyGLM_matrix_carga <- GLM_metrics_matrix_carga$overall["Accuracy"] -->
<!-- kappaGLM_matrix_carga <- GLM_metrics_matrix_carga$overall["Kappa"] -->
<!-- # Métricas por clase -->
<!-- sensitivityGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Sensitivity"] -->
<!-- specificityGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Specificity"] -->
<!-- precisionGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Pos Pred Value"] -->
<!-- recallGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Sensitivity"]  # Igual a sensitivity -->
<!-- f1_scoreGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["F1"] -->
<!-- npvGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Neg Pred Value"] -->
<!-- prevalenceGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Prevalence"] -->
<!-- detection_rateGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Detection Rate"] -->
<!-- balanced_accuracyGLM_matrix_carga <- GLM_metrics_matrix_carga$byClass["Balanced Accuracy"] -->

<!-- # Calcular LR+ y LR- que no vienen directamente en confusionMatrix -->
<!-- LR_plusGLM_matrix_carga <- sensitivityGLM_matrix_carga / (1 - specificityGLM_matrix_carga) -->
<!-- LR_minusGLM_matrix_carga <- (1 - sensitivityGLM_matrix_carga) / specificityGLM_matrix_carga -->

<!-- # Para manejar valores especiales -->
<!-- LR_plusGLM_matrix_carga <- ifelse(is.nan(LR_plusGLM_matrix_carga) | is.infinite(LR_plusGLM_matrix_carga), NA, LR_plusGLM_matrix_carga) -->
<!-- LR_minusGLM_matrix_carga <- ifelse(is.nan(LR_minusGLM_matrix_carga) | is.infinite(LR_minusGLM_matrix_carga), NA, LR_minusGLM_matrix_carga) -->

<!-- # Crear un dataframe con todas las métricas -->
<!-- metricsGLM_matrix_carga <- data.frame( -->
<!--   Metric = c("Accuracy", "Kappa", "Sensitivity", "Specificity", "Precision",  -->
<!--              "F1_Score", "NPV", "Prevalence", "Detection_Rate",  -->
<!--              "Balanced_Accuracy", "LR+", "LR-", "AUC"), -->
<!--   GLM_matrix_carga = c(accuracyGLM_matrix_carga, kappaGLM_matrix_carga, sensitivityGLM_matrix_carga, specificityGLM_matrix_carga, precisionGLM_matrix_carga,  -->
<!--             f1_scoreGLM_matrix_carga, npvGLM_matrix_carga, prevalenceGLM_matrix_carga, detection_rateGLM_matrix_carga,  -->
<!--             balanced_accuracyGLM_matrix_carga, LR_plusGLM_matrix_carga, LR_minusGLM_matrix_carga, AUC_GLM_matrix_carga)) -->

<!-- # Mostrar los resultados -->
<!-- print(metricsGLM_matrix_carga) -->

<!-- # library(irr) -->
<!-- #  -->
<!-- # # Calcular Kappa -->
<!-- # kappa_GLM<- kappa2(cbind(predGLM,y_test)) -->
<!-- #  -->
<!-- # # Ver el valor de Kappa -->
<!-- # print(paste("El índice Kappa es:", round(kappa_GLM$value, 3))) -->
<!-- # kappa_GLM<-round(kappa_GLM$value, 3) -->
<!-- ``` -->


<!-- # Prediccion KNN -->

<!-- ```{r} -->
<!-- #prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test) -->
<!-- prediccionesKNN_matrix_carga<-predict(KNN_matrix_carga, newdata = testData_NOID)#matriz binarizada -->
<!-- print(prediccionesKNN_matrix_carga) -->

<!-- prediccionesKNN_matrix_carga <- factor(as.character(prediccionesKNN_matrix_carga),  -->
<!--                              levels = c("X1", "X2"), -->
<!--                              labels = c("1", "2")) -->
<!-- prediccionesKNN_matrix_carga <- factor(prediccionesKNN_matrix_carga, levels = c("1", "2"), labels = c("Cov.Neg", "Cov.Pos")) -->


<!-- # Obtener las etiquetas reales del conjunto de datos de prueba -->
<!-- y_test <- testData$Y -->
<!-- #y_testDIC <- FeatureMatrix_Dic_df$Y#Matriz binarizada -->

<!-- ``` -->


<!-- ```{r} -->
<!-- # confusion_matrixKNN <- table(prediccionesKNN, y_test) -->
<!-- # # Imprimir la matriz de confusión -->
<!-- # print(confusion_matrixKNN) -->
<!-- KNN_metrics_matrix_carga <- caret::confusionMatrix(prediccionesKNN_matrix_carga, y_test, positive = "Cov.Pos") -->
<!-- ``` -->

<!-- ```{r} -->

<!-- prob_predKNN <- predict(KNN_matrix_carga, newdata = testData_NOID, type = "prob") -->

<!-- # Verifica los nombres de las columnas (clases) -->
<!-- print(colnames(prob_predKNN))  # Deberían ser "1" y "2" o los nombres de las clases -->

<!-- # Asegúrate de que y_test sea numérico con niveles 1 y 2 -->
<!-- y_test_numeric <- as.numeric(testData$Y) -->

<!-- # Calcula la curva ROC usando la probabilidad de la clase positiva ("2") -->
<!-- roc_curve_knn <- roc(response = y_test_numeric, predictor = prob_predKNN[, "X2"], levels = c(1, 2)) -->

<!-- # Calcula el AUC -->
<!-- AUC_KNN_matrix_carga <- auc(roc_curve_knn) -->
<!-- print(paste("El valor de AUC es:", round(AUC_KNN_matrix_carga, 3))) -->

<!-- # Visualiza la curva ROC -->
<!-- plot(roc_curve_knn, main = "Curva ROC - KNN", col = "blue", lwd = 2) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- library(caret) -->
<!-- accuracyKNN_matrix_carga <- KNN_metrics_matrix_carga$overall["Accuracy"] -->
<!-- kappaKNN_matrix_carga <- KNN_metrics_matrix_carga$overall["Kappa"] -->
<!-- # Métricas por clase -->
<!-- sensitivityKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Sensitivity"] -->
<!-- specificityKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Specificity"] -->
<!-- precisionKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Pos Pred Value"] -->
<!-- recallKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Sensitivity"]  # Igual a sensitivity -->
<!-- f1_scoreKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["F1"] -->
<!-- npvKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Neg Pred Value"] -->
<!-- prevalenceKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Prevalence"] -->
<!-- detection_rateKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Detection Rate"] -->
<!-- balanced_accuracyKNN_matrix_carga <- KNN_metrics_matrix_carga$byClass["Balanced Accuracy"] -->

<!-- # Calcular LR+ y LR- que no vienen directamente en confusionMatrix -->
<!-- LR_plusKNN_matrix_carga <- sensitivityKNN_matrix_carga / (1 - specificityKNN_matrix_carga) -->
<!-- LR_minusKNN_matrix_carga <- (1 - sensitivityKNN_matrix_carga) / specificityKNN_matrix_carga -->

<!-- # Para manejar valores especiales -->
<!-- LR_plusKNN_matrix_carga <- ifelse(is.nan(LR_plusKNN_matrix_carga) | is.infinite(LR_plusKNN_matrix_carga), NA, LR_plusKNN_matrix_carga) -->
<!-- LR_minusKNN_matrix_carga <- ifelse(is.nan(LR_minusKNN_matrix_carga) | is.infinite(LR_minusKNN_matrix_carga), NA, LR_minusKNN_matrix_carga) -->

<!-- # Crear un dataframe con todas las métricas -->
<!-- metricsKNN_matrix_carga <- data.frame( -->
<!--   Metric = c("Accuracy", "Kappa", "Sensitivity", "Specificity", "Precision",  -->
<!--              "F1_Score", "NPV", "Prevalence", "Detection_Rate",  -->
<!--              "Balanced_Accuracy", "LR+", "LR-", "AUC"), -->
<!--   KNN_matrix_carga = c(accuracyKNN_matrix_carga, kappaKNN_matrix_carga, sensitivityKNN_matrix_carga, specificityKNN_matrix_carga, precisionKNN_matrix_carga,  -->
<!--             f1_scoreKNN_matrix_carga, npvKNN_matrix_carga, prevalenceKNN_matrix_carga, detection_rateKNN_matrix_carga,  -->
<!--             balanced_accuracyKNN_matrix_carga, LR_plusKNN_matrix_carga, LR_minusKNN_matrix_carga, AUC_KNN_matrix_carga)) -->

<!-- # Mostrar los resultados -->
<!-- print(metricsKNN_matrix_carga) -->

<!-- # library(irr) -->
<!-- #  -->
<!-- # # Calcular Kappa -->
<!-- # kappa_KNN <- kappa2(cbind(prediccionesKNN, y_test)) -->
<!-- #  -->
<!-- # # Ver el valor de Kappa -->
<!-- # print(paste("El índice Kappa es:", round(kappa_KNN$value, 3))) -->
<!-- # kappa_KNN<-round(kappa_KNN$value, 3) -->
<!-- ``` -->



<!-- ```{r} -->
<!-- Train.rf_matrix  <- as.data.frame(trainData)  -->

<!-- Test.rf_matrix <- as.data.frame(testData) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- y_train <- Train.rf_matrix$Y -->
<!-- x_train <- Train.rf_matrix[, setdiff(names(Train.rf_matrix), "Y")] -->
<!-- y_test <- Test.rf_matrix$Y -->
<!-- x_test <- Test.rf_matrix[, setdiff(names(Test.rf_matrix), "Y")] -->

<!-- # Crear el objeto recipe solo con las variables predictoras -->
<!-- objeto_recipe <- recipe(Y ~ ., data = Train.rf_matrix) -->

<!-- # Preparar el objeto recipe -->
<!-- trained_recipe <- prep(objeto_recipe, training = Train.rf_matrix) -->

<!-- # Aplicar bake solo a las variables predictoras -->
<!-- x_train_baked <- bake(trained_recipe, new_data = x_train) -->
<!-- x_test_baked <- bake(trained_recipe, new_data = x_test) -->

<!-- # Volver a juntar Y con los datos procesados -->
<!-- Train.rf_matrix <- cbind(x_train_baked, Y = y_train) -->
<!-- Test.rf_matrix <- cbind(x_test_baked, Y = y_test) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- # Submuestras y repeticiones -->

<!-- # particiones  <- 5 -->
<!-- # repeticiones <- 15 -->
<!-- particiones <- 3 -->
<!-- repeticiones <- 5 -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Specify the tunning configuration (mtry hyperparameter depends on the number of columns) -->
<!-- seed.rf <- 42 -->
<!-- set.seed(seed.rf)  -->

<!-- mtry <- c(1, 2, 3) -->
<!-- min.node.size <- seq(1, 10, 2)  # Reducir el rango -->
<!-- hiperparametros <- expand.grid(mtry =  mtry, -->
<!--                                #min.node.size = smatrix(1, 30, 2), -->
<!--                                min.node.size=min.node.size, -->
<!--                                splitrule = "gini") -->
<!-- ``` -->


<!-- ```{r} -->

<!-- # Seeds -->
<!-- seed.rf <- 42 -->
<!-- set.seed(seed.rf) -->

<!-- seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1) -->

<!-- for (i in 1:(particiones * repeticiones)) { -->
<!--   seeds[[i]] <- sample.int(500, nrow(hiperparametros))  -->
<!-- } -->

<!-- seeds[[(particiones * repeticiones) + 1]] <- sample.int(500, 1) -->

<!-- # Training control -->
<!-- ``` -->



<!-- ```{r} -->
<!-- # Training control -->

<!-- cross_val_ranger <- trainControl( -->
<!--   method = "repeatedcv", -->
<!--   number = particiones, -->
<!--   repeats = repeticiones, -->
<!--   returnResamp = "final", -->
<!--   verboseIter = FALSE, -->
<!--   allowParallel = TRUE, -->
<!--   classProbs = TRUE, -->
<!--   seeds = seeds) -->

<!-- # Training  -->

<!-- # Convertir los niveles de Train.rf$sensi a números también -->

<!-- Train.rf_matrix$Y <- factor(as.numeric(factor(Train.rf_matrix$Y))) -->
<!-- Train.rf_matrix$Y <- factor(Train.rf_matrix$Y, levels = c("1", "2")) -->
<!-- levels(Train.rf_matrix$Y) <- make.names(levels(Train.rf_matrix$Y)) -->

<!-- ``` -->


<!-- ```{r} -->
<!-- class(Train.rf_matrix) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- Train.rf_matrix <- as.data.frame(Train.rf_matrix) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # Primero aseguramos que Train.rf es un dataframe -->
<!-- Train.rf_matrix <- as.data.frame(Train.rf_matrix) -->

<!-- # Convertimos Y a factor -->
<!-- Train.rf_matrix$Y <- as.factor(Train.rf_matrix$Y) -->

<!-- # Definimos número de árboles -->
<!-- #n_trees <- 500 # default -->
<!-- n_trees<-200 -->
<!-- # Establecemos semilla para reproducibilidad -->
<!-- set.seed(80) -->

<!-- # Ejecutamos el entrenamiento -->
<!-- results_matrix <- caret::train(Y ~ ., -->
<!--                 data = Train.rf_matrix,  -->
<!--                 method = "ranger", -->
<!--                 tuneGrid = hiperparametros, -->
<!--                 metric = "Accuracy", -->
<!--                 importance = "impurity", -->
<!--                 trControl = cross_val_ranger, -->
<!--                 num.trees = n_trees) -->
<!--                #allowParallel=FALSE)   -->

<!-- # Vector para probar diferentes números de árboles -->
<!-- #num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500) -->

<!-- ``` -->




<!-- ```{r} -->
<!-- # Definir los valores de num.trees a probar -->
<!-- num_trees_range <- c(10, 50, 100, 200, 500, 1000, 1500) -->

<!-- # Lista para almacenar los modelos -->
<!-- modelos_matriz <- list() -->

<!-- # Establecer semilla para reproducibilidad -->
<!-- set.seed(80) -->

<!-- # Iterar sobre cada cantidad de árboles -->
<!-- for (nt in num_trees_range) { -->
<!--   cat("Entrenando modelo con", nt, "árboles...\n") -->

<!--   modelos_matriz[[as.character(nt)]] <- caret::train( -->
<!--     Y ~ ., -->
<!--     data = Train.rf_matrix, -->
<!--     method = "ranger", -->
<!--     tuneGrid = hiperparametros, -->
<!--     metric = "Accuracy", -->
<!--     importance = "impurity", -->
<!--     trControl = cross_val_ranger, -->
<!--     num.trees = nt -->
<!--   ) -->
<!-- } -->
<!-- ``` -->





<!-- ```{r} -->

<!-- lengths_list <- list( -->
<!--   num_trees = length(num_trees_range), -->
<!--   Accuracy = length(sapply(modelos_matriz, function(m) max(m$results$Accuracy, na.rm = TRUE))), -->
<!--   Kappa = length(sapply(modelos_matriz, function(m) max(m$results$Kappa, na.rm = TRUE))), -->
<!--   mtry = length(sapply(modelos_matriz, function(m) m$bestTune$mtry)), -->
<!--   min.node.size = length(sapply(modelos_matriz, function(m) m$bestTune$min.node.size)) -->
<!-- ) -->

<!-- print(lengths_list) -->

<!--   resultados_modelos <- data.frame( -->
<!--   num_trees = num_trees_range, -->
<!--   Accuracy = sapply(modelos_matriz, function(m) max(m$results$Accuracy, na.rm = TRUE)), -->
<!--   Kappa = sapply(modelos_matriz, function(m) max(m$results$Kappa, na.rm = TRUE)), -->
<!--   mtry = sapply(modelos_matriz, function(m) m$bestTune$mtry), -->
<!--   min.node.size = sapply(modelos_matriz, function(m) m$bestTune$min.node.size) -->
<!-- ) -->

<!-- # Ordenamos los modelos de mejor a peor Accuracy -->
<!-- resultados_modelos <- resultados_modelos[order(-resultados_modelos$Accuracy), ] -->

<!-- print(head(resultados_modelos, 20))  -->

<!-- ``` -->


<!-- ```{r} -->
<!-- # Encontrar el índice del modelo con mejor Accuracy en la tabla de resultados -->
<!-- mejor_idx <- which.max(resultados_modelos$Accuracy) -->

<!-- # Extraer la mejor combinación de hiperparámetros -->
<!-- mejor_num_trees <- resultados_modelos$num_trees[mejor_idx] -->
<!-- mejor_mtry <- resultados_modelos$mtry[mejor_idx] -->
<!-- mejor_min_node_size <- resultados_modelos$min.node.size[mejor_idx] -->

<!-- # Extraer el modelo correspondiente en la lista -->
<!-- mejor_modelo <- resultados_modelos[[as.character(mejor_num_trees)]] -->

<!-- # Mostrar los hiperparámetros seleccionados -->
<!-- cat("Mejor modelo seleccionado:\n") -->
<!-- cat("Número de árboles:", mejor_num_trees, "\n") -->
<!-- cat("mtry:", mejor_mtry, "\n") -->
<!-- cat("min.node.size:", mejor_min_node_size, "\n") -->

<!-- # Mostrar detalles del mejor modelo -->
<!-- print(mejor_modelo) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- # ranger_matriz <- caret::train( -->
<!-- #   Y ~ ., -->
<!-- #   data = Train.rf_matrix,  -->
<!-- #   method = "ranger", -->
<!-- #   tuneGrid = data.frame(mtry = 3, min.node.size = 5, splitrule = "gini"),  -->
<!-- #   metric = "Accuracy", -->
<!-- #   importance = "impurity", -->
<!-- #   trControl = cross_val,  # Si querés usar validación cruzada -->
<!-- #   num.trees = 1000  # Número de árboles fijo -->
<!-- # ) -->
<!-- # print(ranger_matriz) -->
<!-- ranger_matrixcarga_fx<-function(df_train, model, grid, metrica,  num.trees){ -->

<!-- ranger_matriz <- caret::train( -->
<!--   Y ~ ., -->
<!--   data = df_train, -->
<!--   method = "ranger", -->
<!--   tuneGrid = grid, -->
<!--   metric = "Accuracy", -->
<!--   importance = "impurity", -->
<!--   trControl = cross_val_ranger,  # Si querés usar validación cruzada -->
<!--   num.trees=num.trees  # Número de árboles fijo -->
<!-- ) -->

<!-- return(ranger_matriz) -->
<!-- } -->

<!-- # -->

<!-- ranger_matriz<-ranger_matrixcarga_fx(Train.rf_matrix,"ranger",hiperparametros,"Accuracy", num.trees=mejor_num_trees) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- Test.rf_matrix$Y<-as.factor(Test.rf_matrix$Y) -->

<!-- Test.rf_matrix$Y <- as.numeric(Test.rf_matrix$Y) -->
<!-- Test.rf_matrix$Y <- as.factor(Test.rf_matrix$Y) -->
<!-- str(Test.rf_matrix$Y) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- testRF_NOID_matrix <- Test.rf_matrix[, -which(names(Test.rf_matrix) == "Y")] -->

<!-- ``` -->



<!-- ```{r} -->
<!-- #prediccionesRF1<-predict(resultadosRF, newdata = dataNOID_test) -->
<!-- predRANGER_matrix_carga<-predict(results_matrix, newdata = testRF_NOID_matrix)#matriz binarizada -->
<!-- print(predRANGER_matrix_carga) -->
<!-- predRANGER_matrix_carga <- factor(as.character(predRANGER_matrix_carga),  -->
<!--                              levels = c("X1", "X2"), -->
<!--                              labels = c("1", "2")) -->
<!-- predRANGER_matrix_carga <- factor(predRANGER_matrix_carga, levels = c("1", "2"), labels = c("Cov.Neg", "Cov.Pos")) -->



<!-- # Obtener las etiquetas reales del conjunto de datos de prueba -->
<!-- #y_test <- testData$Y -->

<!-- prob_predRanger_matrix <- predict(results_matrix, newdata = testRF_NOID_matrix, type = "prob") -->

<!-- colnames(prob_predRanger_matrix) -->
<!-- # Asegúrate de que y_test sea un factor con los niveles correctos -->
<!-- y_test <- factor(Test.rf_matrix$Y, levels = c(1, 2), labels = c("Cov.Neg", "Cov.Pos")) -->




<!-- ``` -->


<!-- ```{r} -->
<!-- library(pROC) -->

<!-- # Asegúrate de que y_test sea numérico y esté alineado con los niveles 1 y 2 -->
<!-- y_test_numeric <- as.numeric(y_test) -->

<!-- roc_curve <- roc(response = y_test_numeric,  -->
<!--                  predictor = prob_predRanger_matrix[, "X2"],  -->
<!--                  levels = c(1, 2)) -->
<!-- AUC_Ranger_matrix_carga <- auc(roc_curve) -->
<!-- print(paste("El valor de AUC es:", round(AUC_Ranger_matrix_carga, 3))) -->

<!-- # Visualiza la curva ROC -->
<!-- plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2) -->
<!-- #  -->
<!-- # confusion_matrixRANGER <- table(predRANGER_matrix, y_test) -->
<!-- # # Imprimir la matriz de confusión -->
<!-- # print(confusion_matrixRANGER) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- Ranger_metrics_matrix_carga <- caret::confusionMatrix(predRANGER_matrix_carga, y_test, positive = "Cov.Pos") -->
<!-- # Precisión  -->

<!-- library(caret) -->
<!-- accuracyRANGER_matrix_carga <- Ranger_metrics_matrix_carga$overall["Accuracy"] -->
<!-- kappaRANGER_matrix_carga<- Ranger_metrics_matrix_carga$overall["Kappa"] -->
<!-- # Métricas por clase -->
<!-- sensitivityRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Sensitivity"] -->
<!-- specificityRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Specificity"] -->
<!-- precisionRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Pos Pred Value"] -->
<!-- recallRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Sensitivity"]  # Igual a sensitivity -->
<!-- f1_scoreRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["F1"] -->
<!-- npvRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Neg Pred Value"] -->
<!-- prevalenceRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Prevalence"] -->
<!-- detection_rateRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Detection Rate"] -->
<!-- balanced_accuracyRANGER_matrix_carga <- Ranger_metrics_matrix_carga$byClass["Balanced Accuracy"] -->

<!-- # Calcular LR+ y LR- que no vienen directamente en confusionMatrix -->
<!-- LR_plusRANGER_matrix_carga <- sensitivityRANGER_matrix_carga / (1 - specificityRANGER_matrix_carga) -->
<!-- LR_minusRANGER_matrix_carga <- (1 - sensitivityRANGER_matrix_carga) / specificityRANGER_matrix_carga -->

<!-- # Para manejar valores especiales -->
<!-- LR_plusRANGER_matrix_carga <- ifelse(is.nan(LR_plusRANGER_matrix_carga) | is.infinite(LR_plusRANGER_matrix_carga), NA, LR_plusRANGER_matrix_carga) -->
<!-- LR_minusRANGER_matrix_carga <- ifelse(is.nan(LR_minusRANGER_matrix_carga) | is.infinite(LR_minusRANGER_matrix_carga), NA, LR_minusRANGER_matrix_carga) -->

<!-- # Crear un dataframe con todas las métricas -->
<!-- metricsRANGER_matrix_carga <- data.frame( -->
<!--   Metric = c("Accuracy", "Kappa", "Sensitivity", "Specificity", "Precision",  -->
<!--              "F1_Score", "NPV", "Prevalence", "Detection_Rate",  -->
<!--              "Balanced_Accuracy", "LR+", "LR-", "AUC"), -->
<!--   RANGER_matrix_carga = c(accuracyRANGER_matrix_carga, kappaRANGER_matrix_carga, sensitivityRANGER_matrix_carga, specificityRANGER_matrix_carga, precisionRANGER_matrix_carga,  -->
<!--             f1_scoreRANGER_matrix_carga, npvRANGER_matrix_carga, prevalenceRANGER_matrix_carga, detection_rateRANGER_matrix_carga,  -->
<!--             balanced_accuracyRANGER_matrix_carga, LR_plusRANGER_matrix_carga, LR_minusRANGER_matrix_carga, AUC_Ranger_matrix_carga)) -->

<!-- # Mostrar los resultados -->
<!-- print(metricsRANGER_matrix_carga) -->



<!-- ``` -->


